{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bdc6140",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the following paths\n",
    "\n",
    "#reference files\n",
    "REF_TRAIN = '/scratch/ankita.maity/LeWiDi/refs/train_ref_md.tsv'\n",
    "REF_VAL = '/scratch/ankita.maity/LeWiDi/refs/val_ref_md.tsv'\n",
    "REF_TEST = '/scratch/ankita.maity/LeWiDi/refs/test_ref_md.tsv'\n",
    "\n",
    "#logits for train, val and test\n",
    "TRAIN = '/scratch/ankita.maity/LeWiDi/predictions_all/predictions_better_mixer/train_md_new.csv'\n",
    "VAL = '/scratch/ankita.maity/LeWiDi/predictions_all/predictions_better_mixer/val_md_new.csv'\n",
    "TEST = '/scratch/ankita.maity/LeWiDi/predictions_all/predictions_better_mixer/test_md_new.csv'\n",
    "\n",
    "#output path to store the processed train, val and test tsv files in required format\n",
    "TRAIN_TSV = '/scratch/ankita.maity/LeWiDi/predictions_all/submit_better_mixer/train_md_final_new.tsv'\n",
    "VAL_TSV = '/scratch/ankita.maity/LeWiDi/predictions_all/submit_better_mixer/val_md_final_new.tsv'\n",
    "TEST_TSV = '/scratch/ankita.maity/LeWiDi/predictions_all/submit_better_mixer/test_md_final_new.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22b550c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24442e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(f'{TRAIN}')\n",
    "val = pd.read_csv(f'{VAL}')\n",
    "test = pd.read_csv(f'{TEST}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1d0d3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.sort_values('0', ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54cb9e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(['0'], axis=1)\n",
    "val = val.drop(['0'], axis=1)\n",
    "test = test.drop(['0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17dcfd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change according to size of dataframe (md for now)\n",
    "def compute(df):\n",
    "    for i in range(len(df)):\n",
    "        for a in range(1,6):\n",
    "            logit = df[f'{a}'][i]\n",
    "            prediction = torch.sigmoid(torch.as_tensor(logit))\n",
    "            prediction = prediction.detach().cpu().numpy()\n",
    "            df[f'{a}'][i] = 1*(prediction>=0.5)\n",
    "            \n",
    "    \n",
    "    columns = ['hard_label','prob_0', 'prob_1']\n",
    "    df_final = pd.DataFrame(columns=columns)\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        l = []\n",
    "        summ = pd.Series.sum(df.loc[i,:])\n",
    "        if(summ>=3):\n",
    "            l.append(1)\n",
    "        \n",
    "        else:\n",
    "            l.append(0)\n",
    "        \n",
    "        one_prob = summ/5\n",
    "        zero_prob = 1 - one_prob\n",
    "    \n",
    "        l.append(zero_prob)\n",
    "        l.append(one_prob)\n",
    "    \n",
    "        df_final.loc[len(df_final)]=l\n",
    "        \n",
    "    df_final['hard_label'] = df_final['hard_label'].astype(int)\n",
    "    return df_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83d4ad55",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_final = compute(train)\n",
    "val_final = compute (val)\n",
    "test_final = compute(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7290ae90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the train, val and test (for submitting on CodaLab)\n",
    "train_final.to_csv(f'{TRAIN_TSV}', header=None, sep=\"\\t\", index = False)\n",
    "val_final.to_csv(f'{VAL_TSV}', header=None, sep=\"\\t\", index = False)\n",
    "test_final.to_csv(f'{TEST_TSV}', header=None, sep=\"\\t\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "543e2fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(targets_soft, predictions_soft, epsilon = 1e-12):                                \n",
    "    predictions = np.clip(predictions_soft, epsilon, 1. - epsilon)                                      \n",
    "    N = predictions.shape[0]\n",
    "    ce = -np.sum(targets_soft*np.log(predictions+1e-9))/N\n",
    "    return ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d1b6b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_metric(targets_hard, prediction_hard):\n",
    "    f1_wa = sklearn.metrics.f1_score(targets_hard, prediction_hard, average = 'micro')                \n",
    "    return f1_wa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1812a0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data (myfile):\n",
    "    soft = list()\n",
    "    hard = list()\n",
    "    with open(myfile,'r') as f:\n",
    "            for line in f:\n",
    "                line=line.replace('\\n','')\n",
    "                parts=line.split('\\t')\n",
    "                soft.append([float(parts[1]),float(parts[2])])\n",
    "                hard.append(parts[0])\n",
    "    return(soft,hard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4d6186",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross entropy and F1 for train dataset\n",
    "soft_ref, hard_ref = get_data(f'{REF_TRAIN}')\n",
    "soft_pred, hard_pred = get_data(f'{TRAIN_TSV}')\n",
    "\n",
    "soft_score = cross_entropy(soft_ref,soft_pred)\n",
    "hard_score = f1_metric(hard_ref,hard_pred)\n",
    "\n",
    "print(\"cross entropy (soft score): \", soft_score)\n",
    "print(\"micro F1 (hard score): \", hard_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11abe177",
   "metadata": {},
   "outputs": [],
   "source": [
    "#validating on val dataset\n",
    "soft_ref, hard_ref = get_data(f'{REF_VAL}')\n",
    "soft_pred, hard_pred = get_data(f'{VAL_TSV}')\n",
    "\n",
    "soft_score = cross_entropy(soft_ref,soft_pred)\n",
    "hard_score = f1_metric(hard_ref,hard_pred)\n",
    "\n",
    "print(\"cross entropy (soft score): \", soft_score)\n",
    "print(\"micro F1 (hard score): \", hard_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9425eebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scores on test dataset\n",
    "soft_ref, hard_ref = get_data(f'{REF_TEST}')\n",
    "soft_pred, hard_pred = get_data(f'{TEST_TSV}')\n",
    "\n",
    "soft_score = cross_entropy(soft_ref,soft_pred)\n",
    "hard_score = f1_metric(hard_ref,hard_pred)\n",
    "\n",
    "print(\"cross entropy (soft score): \", soft_score)\n",
    "print(\"micro F1 (hard score): \", hard_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
